{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execises: Module 13 - Python Date Time and File Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Datetime Execises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the current day, month, year, hour, minute, and timestamp from the datetime module.\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_day = now.day\n",
    "current_month = now.month\n",
    "current_year = now.year\n",
    "current_hour = now.hour\n",
    "current_minute = now.minute\n",
    "current_timestamp = now.timestamp()\n",
    "\n",
    "print(\"Current day: \", current_day)\n",
    "print(\"Current month: \", current_month)\n",
    "print(\"Current year: \", current_year)\n",
    "print(\"Current hour: \", current_hour)\n",
    "print(\"Current minute: \", current_minute)   \n",
    "print(\"Current timestamp: \", current_timestamp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Format the current date in the following formats: \"%m/%d/%Y, %H:%M:%S\"\n",
    "\n",
    "now = datetime.now()\n",
    "current_date = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "print(\"Current date: \", current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Today is 5 December, 2019. Change this time string to time.\n",
    "\n",
    "time_string = \"5 December, 2019\"\n",
    "time_object = datetime.strptime(time_string, \"%d %B, %Y\")\n",
    "print(time_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Calculate the time difference between now and new year.\n",
    "\n",
    "now = datetime.now()\n",
    "new_year = datetime.strptime(\"1 January, 2020\", \"%d %B, %Y\")\n",
    "time_difference = now - new_year\n",
    "print(time_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Calculate the time difference between 1 January 1970 and now.\n",
    "\n",
    "now = datetime.now()\n",
    "old_date = datetime.strptime(\"1 January, 1970\", \"%d %B, %Y\")\n",
    "time_difference = now - old_date\n",
    "print(time_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 6. Think, what can you use the datetime module for? Examples:\n",
    "- Time series analysis\n",
    "- To get a timestamp of any activities in an application\n",
    "-  Adding post on a blog\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Time Series Analysis**\n",
    "- Manage and analyze datasets indexed by time, such as stock market data or climate records.\n",
    "- Perform operations like filtering data by date ranges or resampling for different time intervals.\n",
    "\n",
    "**2. Timestamps for Activities**\n",
    "- Log specific times for application events, like when a user logs in or performs certain actions.\n",
    "- Track the exact time a file was created, modified, or accessed in a program.\n",
    "\n",
    "**3. Adding Timestamps to Blog Posts**\n",
    "- Automatically record the date and time when a blog post or comment is created.\n",
    "- Display a \"last updated\" timestamp for edited posts.\n",
    "\n",
    "**4. Scheduling Tasks**\n",
    "- Automate reminders, notifications, or tasks based on specific times or intervals.\n",
    "- Trigger functions or scripts to run at particular times (e.g., send an email daily at noon).\n",
    "\n",
    "**5. Calculate Time Differences**\n",
    "- Determine the duration between two events, like the time elapsed between a project start and end.\n",
    "- Calculate a person's age by comparing their birth date with the current date.\n",
    "\n",
    "**6. Formatting Dates**\n",
    "- Convert dates into human-readable formats (e.g., \"January 26, 2025\").\n",
    "- Standardize date formats for consistency across an application.\n",
    "\n",
    "\n",
    "**7. Stopwatch or Timer**\n",
    "- Measure how long a process or function takes to execute.\n",
    "- Track performance metrics for operations in a program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Handling Execises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises: Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Obama speech has 66 lines and 2400 words.\n",
      "The Obama speech has 35 lines and 1085 words.\n",
      "The Obama speech has 48 lines and 1259 words.\n",
      "The Obama speech has 33 lines and 1375 words.\n"
     ]
    }
   ],
   "source": [
    "# Write a function which count number of lines and number of words in a text. All the files are in the data the folder: \n",
    "# a) Read obama_speech.txt file and count number of lines and words \n",
    "# b) Read michelle_obama_speech.txt file and count number of lines and words \n",
    "# c) Read donald_speech.txt file and count number of lines and words \n",
    "# d) Read melina_trump_speech.txt file and count number of lines and words\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def count_lines_and_words(file):\n",
    "    path = Path(file)\n",
    "    content = path.read_text()\n",
    "    lines = content.splitlines()\n",
    "    words = content.split()\n",
    "    return len(lines), len(words)\n",
    "\n",
    "obama_speech_stats = count_lines_and_words('obama_speech.txt')\n",
    "print(\n",
    "    f\"The Obama speech has {obama_speech_stats[0]} \"\n",
    "    f\"lines and {obama_speech_stats[1]} words.\"\n",
    ")\n",
    "\n",
    "michelle_speech_stats = count_lines_and_words('michelle_obama_speech.txt')\n",
    "print(\n",
    "    f\"The Obama speech has {michelle_speech_stats[0]} \"\n",
    "    f\"lines and {michelle_speech_stats[1]} words.\"\n",
    ")\n",
    "\n",
    "donald_speech_stats = count_lines_and_words('donald_speech.txt')\n",
    "print(\n",
    "    f\"The Obama speech has {donald_speech_stats[0]} \"\n",
    "    f\"lines and {donald_speech_stats[1]} words.\"\n",
    ")\n",
    "\n",
    "melina_speech_stats = count_lines_and_words('melina_trump_speech.txt')\n",
    "print(\n",
    "    f\"The Obama speech has {melina_speech_stats[0]} \"\n",
    "    f\"lines and {melina_speech_stats[1]} words.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Spoken Languages:\n",
      "English: 91\n",
      "French: 45\n",
      "Arabic: 25\n",
      "Spanish: 24\n",
      "Portuguese: 9\n",
      "Russian: 9\n",
      "Dutch: 8\n",
      "German: 7\n",
      "Chinese: 5\n",
      "Serbian: 4\n"
     ]
    }
   ],
   "source": [
    "# 2. Read the countries_data.json data file in data directory, create a function that finds the ten most spoken languages\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "def ten_most_spoken_languages(countries):\n",
    "    \"\"\" Find ten most spoken languages in the world \"\"\"\n",
    "    language_counter = Counter()\n",
    "    for country in countries:\n",
    "        languages = country['languages']\n",
    "        language_counter.update(languages)\n",
    "    return language_counter.most_common(10)\n",
    "\n",
    "path = Path('countries_data.json')\n",
    "countries_data = json.loads(path.read_text(encoding='utf-8'))\n",
    "\n",
    "print('Most Spoken Languages:')\n",
    "most_spoken_languages = ten_most_spoken_languages(countries_data)\n",
    "for key, value in most_spoken_languages:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Populated Countries:\n",
      " Country: China, Population: 1377422166\n",
      " Country: India, Population: 1295210000\n",
      " Country: United States of America, Population: 323947000\n",
      " Country: Indonesia, Population: 258705000\n",
      " Country: Brazil, Population: 206135893\n",
      " Country: Pakistan, Population: 194125062\n",
      " Country: Nigeria, Population: 186988000\n",
      " Country: Bangladesh, Population: 161006790\n",
      " Country: Russian Federation, Population: 146599183\n",
      " Country: Japan, Population: 126960000\n"
     ]
    }
   ],
   "source": [
    "# 3. Read the countries_data.json data file in data directory, create a function that finds the ten most populated countries\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "def ten_most_populated_countries(countries):\n",
    "    \"\"\" Find ten most populated countries in the world \"\"\"\n",
    "    country_counter = Counter()\n",
    "    for country in countries:\n",
    "        country_name = country['name']\n",
    "        population = country['population']\n",
    "        country_counter[country_name] = population\n",
    "    return country_counter.most_common(10)\n",
    "\n",
    "path = Path('countries_data.json')\n",
    "countries_data = json.loads(path.read_text(encoding='utf-8'))\n",
    "\n",
    "print('Most Populated Countries:')\n",
    "most_populated_countries = ten_most_populated_countries(countries_data)\n",
    "for key, value in most_populated_countries:\n",
    "    print(f\" Country: {key}, Population: {value}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises: Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['marquard@uct.ac', 'postmaster@collab.sakaiproject', 'm05ECIaH010327@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'marquard@uct.ac', 'source@collab.sakaiproject', 'marquard@uct.ac', 'marquard@uct.ac', 'louis@media.berkeley', 'postmaster@collab.sakaiproject', 'm04N8v6O008125@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'louis@media.berkeley', 'source@collab.sakaiproject', 'louis@media.berkeley', 'louis@media.berkeley', 'zqian@umich.edu', 'postmaster@collab.sakaiproject', 'm04L92hb007923@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'zqian@umich.edu', 'source@collab.sakaiproject', 'zqian@umich.edu', 'zqian@umich.edu', 'rjlowe@iupui.edu', 'postmaster@collab.sakaiproject', 'm04Kiem3007881@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'rjlowe@iupui.edu', 'source@collab.sakaiproject', 'rjlowe@iupui.edu', 'rjlowe@iupui.edu', 'zqian@umich.edu', 'postmaster@collab.sakaiproject', 'm04K1cO0007738@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'zqian@umich.edu', 'source@collab.sakaiproject', 'zqian@umich.edu', 'zqian@umich.edu', 'zqian@umich.edu', 'rjlowe@iupui.edu', 'postmaster@collab.sakaiproject', 'm04JmdwO007705@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'rjlowe@iupui.edu', 'source@collab.sakaiproject', 'rjlowe@iupui.edu', 'rjlowe@iupui.edu', 'cwen@iupui.edu', 'postmaster@collab.sakaiproject', 'm04GZQGZ007313@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'cwen@iupui.edu', 'source@collab.sakaiproject', 'cwen@iupui.edu', 'cwen@iupui.edu', 'hu2@iupui.edu', 'cwen@iupui.edu', 'postmaster@collab.sakaiproject', 'm04GX6eG007292@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'cwen@iupui.edu', 'source@collab.sakaiproject', 'cwen@iupui.edu', 'cwen@iupui.edu', 'hu2@iupui.edu', 'gsilver@umich.edu', 'postmaster@collab.sakaiproject', 'm04GB1Lb007221@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'gsilver@umich.edu', 'source@collab.sakaiproject', 'gsilver@umich.edu', 'gsilver@umich.edu', 'gsilver@umich.edu', 'postmaster@collab.sakaiproject', 'm04GA5KP007209@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'gsilver@umich.edu', 'source@collab.sakaiproject', 'gsilver@umich.edu', 'gsilver@umich.edu', 'zqian@umich.edu', 'postmaster@collab.sakaiproject', 'm04G9EuX007197@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'zqian@umich.edu', 'source@collab.sakaiproject', 'zqian@umich.edu', 'zqian@umich.edu', 'gsilver@umich.edu', 'postmaster@collab.sakaiproject', 'm04G8d7w007184@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'gsilver@umich.edu', 'source@collab.sakaiproject', 'gsilver@umich.edu', 'gsilver@umich.edu', 'wagnermr@iupui.edu', 'postmaster@collab.sakaiproject', 'm04Fb6Ci007092@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'wagnermr@iupui.edu', 'source@collab.sakaiproject', 'wagnermr@iupui.edu', 'wagnermr@iupui.edu', 'zqian@umich.edu', 'postmaster@collab.sakaiproject', 'm04FFv42007050@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'zqian@umich.edu', 'source@collab.sakaiproject', 'zqian@umich.edu', 'zqian@umich.edu', 'antranig@caret.cam', 'postmaster@collab.sakaiproject', 'm04F21Jo007031@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'antranig@caret.cam', 'source@collab.sakaiproject', 'antranig@caret.cam', 'antranig@caret.cam', 'ramasammycook@gmail.com', 'postmaster@collab.sakaiproject', 'm04E3psW006926@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'ramasammycook@gmail.com', 'source@collab.sakaiproject', 'ramasammycook@gmail.com', 'ramasammycook@gmail.com', 'horwitz@uct.ac', 'postmaster@collab.sakaiproject', 'm04C0gfK006793@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'horwitz@uct.ac', 'source@collab.sakaiproject', 'horwitz@uct.ac', 'horwitz@uct.ac', 'horwitz@uct.ac', 'horwitz@uct.ac', 'postmaster@collab.sakaiproject', 'm04B6lK3006677@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'horwitz@uct.ac', 'source@collab.sakaiproject', 'horwitz@uct.ac', 'horwitz@uct.ac', 'horwitz@uct.ac', 'postmaster@collab.sakaiproject', 'm049lUxo006517@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'horwitz@uct.ac', 'source@collab.sakaiproject', 'horwitz@uct.ac', 'horwitz@uct.ac', 'josrodri@iupui.edu', 'horwitz@uct.ac', 'postmaster@collab.sakaiproject', 'm049W2i5006493@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'horwitz@uct.ac', 'source@collab.sakaiproject', 'horwitz@uct.ac', 'horwitz@uct.ac', 'josrodri@iupui.edu', 'marquard@uct.ac', 'postmaster@collab.sakaiproject', 'm0495rWB006420@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'marquard@uct.ac', 'source@collab.sakaiproject', 'marquard@uct.ac', 'marquard@uct.ac', 'louis@media.berkeley', 'postmaster@collab.sakaiproject', 'm040NpCc005473@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'louis@media.berkeley', 'source@collab.sakaiproject', 'louis@media.berkeley', 'louis@media.berkeley', 'louis@media.berkeley', 'postmaster@collab.sakaiproject', 'm03MGhDa005292@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'louis@media.berkeley', 'source@collab.sakaiproject', 'louis@media.berkeley', 'louis@media.berkeley', 'ray@media.berkeley', 'postmaster@collab.sakaiproject', 'm03M5Ea7005273@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'ray@media.berkeley', 'source@collab.sakaiproject', 'ray@media.berkeley', 'ray@media.berkeley', 'cwen@iupui.edu', 'postmaster@collab.sakaiproject', 'm03LX3gG005191@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'cwen@iupui.edu', 'source@collab.sakaiproject', 'cwen@iupui.edu', 'cwen@iupui.edu', 'cwen@iupui.edu', 'postmaster@collab.sakaiproject', 'm03LRUqH005177@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'cwen@iupui.edu', 'source@collab.sakaiproject', 'cwen@iupui.edu', 'cwen@iupui.edu', 'wagnermr@iupui.edu', 'cwen@iupui.edu', 'postmaster@collab.sakaiproject', 'm03LMFo4005148@nakamura.uits', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'source@collab.sakaiproject', 'cwen@iupui.edu', 'source@collab.sakaiproject', 'cwen@iupui.edu', 'cwen@iupui.edu', 'wagnermr@iupui.edu']\n"
     ]
    }
   ],
   "source": [
    "# 4.Extract all incoming email addresses as a list from the email_exchange_big.txt file\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path('email_exchange_big.txt')\n",
    "content = path.read_text()\n",
    "lines = content.splitlines()\n",
    "email_addresses = []\n",
    "for line in lines:\n",
    "    email_addresses.extend(re.findall(r'\\b\\w+@\\w+\\.\\w+\\b', line)) # use regular\n",
    "    # expression to find email addresses\n",
    "print(email_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 120), ('and', 107), ('of', 81), ('to', 66), ('our', 58), ('we', 50), ('a', 48), ('that', 47), ('is', 36), ('in', 22)]\n"
     ]
    }
   ],
   "source": [
    "# 5. Find the most common words in the English language. Call the name of your function find_most_common_words, it will take two parameters \n",
    "# - a string or a file and a positive integer, indicating the number of words. Your function will return an array of tuples in descending order\n",
    "\n",
    "import re\n",
    "\n",
    "def find_most_common_words(filename,num_words):\n",
    "    pattern = r'[\\-–—]'\n",
    "    words_dict = {}\n",
    "    try:\n",
    "        with open(filename) as file_obj:\n",
    "            text = file_obj.read()\n",
    "            text = re.sub(pattern, '',text)\n",
    "            word_list = text.split()\n",
    "            for word in word_list:\n",
    "                if word in words_dict:\n",
    "                    words_dict[word] += 1\n",
    "                else:\n",
    "                    words_dict[word] = 1\n",
    "    except FileNotFoundError:\n",
    "        print('Sorry file does not exist')\n",
    "        return None\n",
    "   \n",
    "    sorted_dict_val_list = dict(sorted(words_dict.items(), key=lambda val: val[1], reverse=True))\n",
    "    return list(sorted_dict_val_list.items())[:num_words]\n",
    "\n",
    "x = find_most_common_words('obama_speech.txt',10)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama = [('the', 120), ('and', 107), ('of', 81), ('to', 66), ('our', 58), ('we', 50), ('a', 48), ('that', 47), ('is', 36), ('in', 22)]\n",
      "Michelle = [('and', 47), ('to', 37), ('the', 34), ('a', 22), ('that', 20), ('my', 19), ('of', 18), ('our', 17), ('I', 16), ('in', 16)]\n",
      "Trump = [('the', 61), ('and', 53), ('will', 40), ('of', 38), ('to', 32), ('our', 30), ('we', 26), ('is', 20), ('We', 15), ('America', 14)]\n",
      "Melina = [('and', 73), ('to', 54), ('the', 48), ('I', 28), ('is', 28), ('for', 27), ('of', 25), ('a', 22), ('that', 19), ('Donald', 17)]\n"
     ]
    }
   ],
   "source": [
    "# 6. Use the function, find_most_frequent_words to find: \n",
    "# a) The ten most frequent words used in Obama's speech \n",
    "# b) The ten most frequent words used in Michelle's speech \n",
    "# c) The ten most frequent words used in Trump's speech \n",
    "# d) The ten most frequent words used in Melina's speech\n",
    "\n",
    "\n",
    "obama = find_most_common_words('obama_speech.txt',10)\n",
    "print(f'Obama = {obama}')\n",
    "michelle = find_most_common_words('michelle_obama_speech.txt',10)\n",
    "print(f'Michelle = {michelle}')\n",
    "trump = find_most_common_words('donald_speech.txt',10)\n",
    "print(f'Trump = {trump}')\n",
    "melina = find_most_common_words('melina_trump_speech.txt',10)\n",
    "print(f'Melina = {melina}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump and Obama speech has similarity score of 9.15%\n",
      "Obama and Obama speech has similarity score of 100.0%\n"
     ]
    }
   ],
   "source": [
    "# 7. Write a python application that checks similarity between two texts. It takes a file or a string as a parameter and it will evaluate the similarity of the two texts. \n",
    "# For instance check the similarity between the transcripts of Michelle's and Melina's speech. You may need a couple of functions, function to clean the text(clean_text), \n",
    "# function to remove support words(remove_support_words) and finally to check the similarity(check_text_similarity). List of stop words are in the data directory\n",
    "\n",
    "\n",
    "from stops_words import stop_words\n",
    "\n",
    "def clean_text(text):\n",
    "    pattern = r'[%$@&#;!\\n–-]'\n",
    "    return re.sub(pattern,'',text)\n",
    "\n",
    "def remove_support_words(words_list):\n",
    "    stop_words_list = stop_words\n",
    "    return [word.lower() for word in words_list if word.lower() not in stop_words_list and word != '']\n",
    "def similarity(filepath_1,filepath_2):\n",
    "    try:\n",
    "        with open(filepath_1) as f_obj:\n",
    "            text_1 = f_obj.read()\n",
    "        with open(filepath_2) as f_obj:\n",
    "            text_2 = f_obj.read()\n",
    "    except FileNotFoundError:\n",
    "        print(\"File Path not found!\")\n",
    "        return None\n",
    "    \n",
    "    cleaned_text_1 = clean_text(text_1)\n",
    "    cleaned_text_2 = clean_text(text_2)\n",
    "\n",
    "    unique_no_support_1 = set(remove_support_words(cleaned_text_1.split()))\n",
    "\n",
    "    unique_no_support_2 = set(remove_support_words(cleaned_text_2.split()))\n",
    "\n",
    "    similar_words = [word for word in unique_no_support_1 if word in unique_no_support_2]\n",
    "\n",
    "    all_word_list =  unique_no_support_1.union(unique_no_support_2)\n",
    "\n",
    "    percent_score = (len(similar_words) / len(all_word_list)) * 100\n",
    "\n",
    "    \n",
    "    return round(percent_score,2)\n",
    "    \n",
    "    \n",
    "trump_vs_obama = similarity('donald_speech.txt','obama_speech.txt')\n",
    "\n",
    "print('Trump and Obama speech has similarity score of {}%'.format(trump_vs_obama))\n",
    "\n",
    "   \n",
    "obama_vs_obama = similarity('obama_speech.txt','obama_speech.txt')\n",
    "\n",
    "print('Obama and Obama speech has similarity score of {}%'.format(obama_vs_obama))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 3),\n",
       " ('and', 3),\n",
       " ('THIS', 3),\n",
       " ('EBOOK', 3),\n",
       " ('OF', 3),\n",
       " ('at', 3),\n",
       " ('the', 3),\n",
       " ('Project', 2),\n",
       " ('Gutenberg', 2),\n",
       " ('Romeo', 2)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Find the 10 most repeated words in the romeo_and_juliet.txt\n",
    "\n",
    "find_most_common_words('romeo_and_juliet.txt',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines containing 'python' or 'Python': 179\n",
      "Number of lines containing 'JavaScript', 'javascript' or 'Javascript': 184\n",
      "Number of lines containing 'Java' but not 'JavaScript': 53\n"
     ]
    }
   ],
   "source": [
    "# 9. Read the hacker news csv file and find out: \n",
    "# a) Count the number of lines containing python or Python \n",
    "# b) Count the number lines containing JavaScript, javascript or Javascript \n",
    "# c) Count the number lines containing Java and not JavaScript\n",
    "\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "def count_lines_with_keywords(file_path, keywords):\n",
    "    \"\"\"Count the number of lines containing any of the specified keywords.\"\"\"\n",
    "    count = 0\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            line = ' '.join(row)\n",
    "            if any(keyword in line for keyword in keywords):\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def count_lines_with_java_not_javascript(file_path):\n",
    "    \"\"\"Count the number of lines containing 'Java' but not 'JavaScript'.\"\"\"\n",
    "    count = 0\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            line = ' '.join(row)\n",
    "            if 'Java' in line and 'JavaScript' not in line and 'javascript' not in line and 'Javascript' not in line:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "file_path = Path('hacker_news.csv')\n",
    "\n",
    "# Count lines containing 'python' or 'Python'\n",
    "python_count = count_lines_with_keywords(file_path, ['python', 'Python'])\n",
    "print(f\"Number of lines containing 'python' or 'Python': {python_count}\")\n",
    "\n",
    "# Count lines containing 'JavaScript', 'javascript' or 'Javascript'\n",
    "javascript_count = count_lines_with_keywords(file_path, ['JavaScript', 'javascript', 'Javascript'])\n",
    "print(f\"Number of lines containing 'JavaScript', 'javascript' or 'Javascript': {javascript_count}\")\n",
    "\n",
    "# Count lines containing 'Java' but not 'JavaScript'\n",
    "java_not_javascript_count = count_lines_with_java_not_javascript(file_path)\n",
    "print(f\"Number of lines containing 'Java' but not 'JavaScript': {java_not_javascript_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
